<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-12-21T09:32:56-06:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Rckwzrd’s Reference</title><subtitle>Matt Rhoads |</subtitle><entry><title type="html">The Lego Themes Table</title><link href="http://localhost:4000/2022/11/14/the-lego-themes-table.html" rel="alternate" type="text/html" title="The Lego Themes Table" /><published>2022-11-14T00:00:00-06:00</published><updated>2022-11-14T00:00:00-06:00</updated><id>http://localhost:4000/2022/11/14/the-lego-themes-table</id><content type="html" xml:base="http://localhost:4000/2022/11/14/the-lego-themes-table.html"><![CDATA[<p>In this post we will bulk load 498 unique lego themes from the Rebrickable API into a local lego database. This task leverages the API and database operations established in the <a href="https://rckwzrd.github.io/2022/09/26/counting-lego-bricks.html">Counting Lego Bricks</a> and <a href="https://rckwzrd.github.io/2022/10/26/creating-a-lego-database.html">Creating a Lego Database</a> posts. Because we already wrote functions for requesting data and interacting with the database hydrating the themes table is a straightforward operation.</p>

<p>For context lets quickly review the schema for themes table in the lego database:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>sqlite3 lego.db 
SQLite version 3.37.2 2022-01-06 13:25:41
...
sqlite&gt; .schema
CREATE TABLE themes <span class="o">(</span>
            theme_id INT PRIMARY KEY,
            theme_name TEXT NOT NULL
        <span class="o">)</span><span class="p">;</span>
</code></pre></div></div>

<p>The themes table has been provisioned to accept a <code class="language-plaintext highlighter-rouge">theme_id</code> integer as a primary key and a <code class="language-plaintext highlighter-rouge">theme_name</code> as a non-null text object. These are the two pieces of data that will be collected from the Rebrickable API and dropped into this table for permanent retention.</p>

<p>The procedure below requires minimal new code to execute the bulk load:</p>

<ol>
  <li>Define a bulk load python function and SQL statement</li>
  <li>Request theme data and format for insertion</li>
  <li>Wrap the procedure in a python function and execute</li>
  <li>Verify the themes table was successfully hydrated</li>
</ol>

<h2 id="function-and-statement">Function and Statement</h2>

<p>The bulk load function follows patterns established for interacting with the lego database in <code class="language-plaintext highlighter-rouge">lego_db.py</code>. The only additional components are the <code class="language-plaintext highlighter-rouge">with conn</code> context manager and the <code class="language-plaintext highlighter-rouge">conn.executemany()</code> method:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># lego_db.py
</span><span class="k">def</span> <span class="nf">load_table</span><span class="p">(</span><span class="n">conn</span><span class="p">,</span> <span class="n">load_sql</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">conn</span><span class="p">:</span>
            <span class="n">conn</span><span class="p">.</span><span class="n">executemany</span><span class="p">(</span><span class="n">load_sql</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"Table Hydrated"</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">sqlite3</span><span class="p">.</span><span class="n">Error</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">e</span>
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">conn.executemany()</code> method accepts a SQL insert statement string and a blob of data as arguements. This method can be used to load blobs of data in one call making it a good fit for the bulk load use case. One caveat is that the data passed needs to be a list of tuples. This requirement will be handled after the themes data is requested.</p>

<p>The <code class="language-plaintext highlighter-rouge">with conn</code> context manager wraps the <code class="language-plaintext highlighter-rouge">conn.executemany()</code> call and commits the insert transactions taking place. If any sort of exception is thrown the context manager will roll back the transactions and protect the database. More information on the context manager can be found in the <a href="https://docs.python.org/3/library/sqlite3.html#sqlite3-connection-context-manager">context manager documentation</a></p>

<p>The SQL statement used to execute the bulk load is deceptively simple:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">load_sql</span> <span class="o">=</span> <span class="s">"""
    INSERT INTO themes VALUES(?, ?)
"""</span>
</code></pre></div></div>
<p>Loading data into a the themes table is triggered by the <code class="language-plaintext highlighter-rouge">INSERT INTO themes</code> statement. The key piece is the <code class="language-plaintext highlighter-rouge">VALUES</code> statement. The <code class="language-plaintext highlighter-rouge">?, ?</code> expression is SQL placeholder syntax that will insert a tuple of <code class="language-plaintext highlighter-rouge">theme_id</code> and <code class="language-plaintext highlighter-rouge">theme_name</code> into the themes table. The placeholder syntax is an important tool for loading data and enforcing security. Additional details can be found in the <a href="https://docs.python.org/3/library/sqlite3.html#sqlite3-placeholders">placeholder documentation</a>.</p>

<h2 id="request-and-format">Request and Format</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_themes</span><span class="p">():</span>
    <span class="n">url</span> <span class="o">=</span> <span class="s">"https://rebrickable.com/api/v3/lego/themes/?page=1&amp;page_size=1000"</span>
    <span class="n">req</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
    <span class="n">time</span><span class="p">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">1.1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">req</span><span class="p">.</span><span class="n">json</span><span class="p">()[</span><span class="s">"results"</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">themes</span> <span class="o">=</span> <span class="p">[(</span><span class="n">i</span><span class="p">[</span><span class="s">"id"</span><span class="p">],</span> <span class="n">i</span><span class="p">[</span><span class="s">"name"</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">get_themes</span><span class="p">()]</span>
</code></pre></div></div>

<h2 id="wrap-and-execute">Wrap and Execute</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code></code></pre></div></div>

<h2 id="verify-data">Verify Data</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code></code></pre></div></div>]]></content><author><name></name></author><summary type="html"><![CDATA[In this post we will bulk load 498 unique lego themes from the Rebrickable API into a local lego database. This task leverages the API and database operations established in the Counting Lego Bricks and Creating a Lego Database posts. Because we already wrote functions for requesting data and interacting with the database hydrating the themes table is a straightforward operation.]]></summary></entry><entry><title type="html">Creating A Lego Database</title><link href="http://localhost:4000/2022/10/26/creating-a-lego-database.html" rel="alternate" type="text/html" title="Creating A Lego Database" /><published>2022-10-26T00:00:00-05:00</published><updated>2022-10-26T00:00:00-05:00</updated><id>http://localhost:4000/2022/10/26/creating-a-lego-database</id><content type="html" xml:base="http://localhost:4000/2022/10/26/creating-a-lego-database.html"><![CDATA[<p>If you spend time around lego sets you will notice that there is a structure between sets, bricks, and themes that is an obvious fit for a relational database system. In this post we will provision a SQLite3 database with Python to hold set and theme information. This will expand on the <a href="https://rckwzrd.github.io/2022/09/26/counting-lego-bricks.html">Counting Lego Bricks</a> post with the end goal of pumping lego data from the Rebrickable API into our local database.</p>

<p><a href="https://www.sqlite.org/index.html">SQLite3</a> is a fast and lightweight SQL database engine that lives on a hard drive. It does not have the overhead of traditional client-server database engines making it easy to use for small projects. We will interact with SQLite3 using the <a href="https://docs.python.org/3/library/sqlite3.html">Python API</a> included in the standard library. The efficiency of SQLite3 combined with the utility of Python provides a good solution for creating and maintaining a lego database.</p>

<p>Before we can start pumping lego data into the database we need to initialize a SQLite3 data store, create methods to operate on the database, and define the structure of tables that hold data. These operations are effectively SQL statements held in strings and passed to the SQLite3 engine via the Python API. The following actions for provisioning a database can be recorded in a Python module and reused as the pipeline grows:</p>

<ol>
  <li>create connection</li>
  <li>define sets table</li>
  <li>define themes table</li>
  <li>create tables</li>
  <li>close connection</li>
</ol>

<h2 id="installing-sqlite3">Installing SQLite3</h2>

<p>Before we can provision the lego databse we need to install SQLite on a personal linux machine. Fortunately installing SQLite3 is a simple task.</p>

<p>First check if SQLite3 is installed by running <code class="language-plaintext highlighter-rouge">which</code> in a terminal:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>which sqlite3
/usr/bin/sqlite3
</code></pre></div></div>

<p>If the output returns a path to the SQLite3 binary proceed. If not run the following <code class="language-plaintext highlighter-rouge">apt install</code> command:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>apt <span class="nb">install </span>sqlite3
</code></pre></div></div>

<p>Confirm that SQLite3 is installed with by checking the <code class="language-plaintext highlighter-rouge">version</code>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>sqlite3 <span class="nt">--version</span>
3.37.2 2022-01-06 13:25:41 872ba256cbf61d9290b571c0e6d82a20c224ca3ad82971edc46b29818d5dalt1
</code></pre></div></div>

<p>Now we can begin building our SQLite3 Python module!</p>

<h2 id="creating-a-connection">Creating a connection</h2>

<p>One of the greatest advantages of SQLite3 is that the entire database is contained in one file. To initialize a database pass a file name with the <code class="language-plaintext highlighter-rouge">.db</code> extension to <code class="language-plaintext highlighter-rouge">sqlite3.connect()</code>. If the database with the passed name is not is not found a new database will be implictly generated. Calling <code class="language-plaintext highlighter-rouge">sqlite3.connect()</code> returns a connection object that is used to run other actions against the database.</p>

<p>Becuase we want to be able to initialize a database and connect on demand the operation is wrapped in the <code class="language-plaintext highlighter-rouge">connect_db()</code> function. This function takes a database string as an arguement, returns a database connection, and fails gracefully if something goes awry:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sqlite3</span>

<span class="k">def</span> <span class="nf">connect_db</span><span class="p">(</span><span class="n">db_file</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">conn</span> <span class="o">=</span> <span class="n">sqlite3</span><span class="p">.</span><span class="n">connect</span><span class="p">(</span><span class="n">db_file</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Connection Created"</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">sqlite3</span><span class="p">.</span><span class="n">Error</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">e</span>
    <span class="k">return</span> <span class="n">conn</span>
</code></pre></div></div>

<h2 id="define-themes-table">Define Themes Table</h2>

<p>Now we need to define the structure of the lego themes table using the following SQL <code class="language-plaintext highlighter-rouge">CREATE TABLE</code> statement:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">create_themes_sql</span> <span class="o">=</span> <span class="s">"""
    CREATE TABLE IF NOT EXISTS themes (
        theme_id TEXT PRIMARY KEY,
        theme_name TEXT NOT NULL
    );
    """</span>
</code></pre></div></div>

<p>This statment checks first if the <code class="language-plaintext highlighter-rouge">themes</code> table exists, creates one if it doesn’t, and then declares the constraints for two fields. The <code class="language-plaintext highlighter-rouge">theme_id</code> is an text field and primary key representing the relational link to other tables in the database. The <code class="language-plaintext highlighter-rouge">theme_name</code> is a text field that will only accept non null entries. In practical terms the <code class="language-plaintext highlighter-rouge">theme_id</code> identifies each unique lego theme and the <code class="language-plaintext highlighter-rouge">theme_name</code> gives the full descriptive name.</p>

<h2 id="define-sets-table">Define Sets Table</h2>

<p>Now we will use a slightly more complicated <code class="language-plaintext highlighter-rouge">CREATE TABLE</code> statement to define the structure of the lego sets table:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">create_sets_sql</span> <span class="o">=</span> <span class="s">"""
    CREATE TABLE IF NOT EXISTS sets (
        set_num TEXT PRIMARY KEY,
        set_name TEXT NOT NULL,
        set_year INT NOT NULL,
        theme_id INT NOT NULL,
        num_parts INT NOT NULL,
        FOREIGN KEY (theme_id) REFERENCES themes (theme_id)
    );
        """</span>
</code></pre></div></div>

<p>Following the same pattern as above, this statement checks if the <code class="language-plaintext highlighter-rouge">sets</code> table exists, creates if required, and then declares the constraints for five fields. The <code class="language-plaintext highlighter-rouge">set_num</code> is a text field and primary key for the table. The <code class="language-plaintext highlighter-rouge">set_name</code> is a non null text field. The <code class="language-plaintext highlighter-rouge">set_year</code>, <code class="language-plaintext highlighter-rouge">theme_id</code>, and <code class="language-plaintext highlighter-rouge">num_parts</code> are all non null integer fields. The <code class="language-plaintext highlighter-rouge">FOREIGN KEY</code> statement links the <code class="language-plaintext highlighter-rouge">theme_id</code> in the <code class="language-plaintext highlighter-rouge">sets</code> table to primary <code class="language-plaintext highlighter-rouge">theme_id</code> key in the <code class="language-plaintext highlighter-rouge">themes</code> table. Again in practical terms the <code class="language-plaintext highlighter-rouge">set_num</code> identifies each lego set, the <code class="language-plaintext highlighter-rouge">set_name</code> gives the official set name, the <code class="language-plaintext highlighter-rouge">set_year</code> list the year the set was introduced, the <code class="language-plaintext highlighter-rouge">num_parts</code> gives the number of bricks in the set. The <code class="language-plaintext highlighter-rouge">theme_id</code> gives the identifier for the theme the set belongs to and can be used to reference theme data held in the <code class="language-plaintext highlighter-rouge">themes</code> table.</p>

<h2 id="creating-the-tables">Creating the Tables</h2>

<p>Note that both of the above SQL statements are wrapped in triple quotes and assigned to the variables <code class="language-plaintext highlighter-rouge">create_theme_sql</code> and <code class="language-plaintext highlighter-rouge">create_sets_sql</code>. While they contain valid SQL statements, these variables are simply python strings. In order to create the tables the statements need to be passed to the database, evaluated by the SQLite3 engine, and executed. We will use the <code class="language-plaintext highlighter-rouge">create_table()</code> function to carry out this tranasction for both the themes and sets tables:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_table</span><span class="p">(</span><span class="n">conn</span><span class="p">,</span> <span class="n">table_sql</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">conn</span><span class="p">.</span><span class="n">cursor</span><span class="p">()</span>
        <span class="n">c</span><span class="p">.</span><span class="n">execute</span><span class="p">(</span><span class="n">table_sql</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Table Created"</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">sqlite3</span><span class="p">.</span><span class="n">Error</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">e</span>
</code></pre></div></div>

<p>This function accepts a database connection and a <code class="language-plaintext highlighter-rouge">CREATE TABLE</code> string as arguements. The <code class="language-plaintext highlighter-rouge">cursor()</code> method is called on the connection to generate a cursor object. The cursor is the primary tool for executing SQL statements against a database and capturing the returned response if applicable. The <code class="language-plaintext highlighter-rouge">CREATE TABLE</code> statement is now passed to the cursor’s <code class="language-plaintext highlighter-rouge">execute()</code> method to be evaluated and the table is initialzed. This operation is wrapped in a <code class="language-plaintext highlighter-rouge">try/except</code> block to responsibly handle errors.</p>

<h2 id="closing-the-connection">Closing the connection</h2>

<p>After intitializing the database by opening a connection and then creating tables we need to close the connection. Closing the database connection will explicitly commit the table creation transactions and protect the integrity of the database. It is always a good practice to close a SQLite3 database connection with the <code class="language-plaintext highlighter-rouge">close()</code> method. In our case the connection closure is wrapped in the <code class="language-plaintext highlighter-rouge">close_db()</code> function and includes a bit of error handling:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">close_db</span><span class="p">(</span><span class="n">conn</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">conn</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Connection Closed"</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">sqlite3</span><span class="p">.</span><span class="n">Error</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">e</span>
</code></pre></div></div>

<h2 id="full-script">Full Script</h2>

<p>The database initialization and table creation should be performed in the following sequence:</p>

<ol>
  <li>create connection</li>
  <li>define sets table</li>
  <li>define themes table</li>
  <li>create tables</li>
  <li>close connection</li>
</ol>

<p>Because we chose to wrap the operations in functions the provisioning sequence can be organized in a <code class="language-plaintext highlighter-rouge">main()</code> function at the end of the script. The <code class="language-plaintext highlighter-rouge">main()</code> function can in turn be fired by running <code class="language-plaintext highlighter-rouge">python -m lego-db.py</code> in a terminal. If all goes as planned print statements detailing each step will print in quick succession. The full script is included below, with the <code class="language-plaintext highlighter-rouge">main()</code> function and corresponding <code class="language-plaintext highlighter-rouge">__name__</code> check.</p>

<p>At this point we have provisioned the lego database and are ready to continue building the lego data pipeline.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># lego-db.py
</span>
<span class="kn">import</span> <span class="nn">sqlite3</span>


<span class="k">def</span> <span class="nf">connect_db</span><span class="p">(</span><span class="n">db_file</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">conn</span> <span class="o">=</span> <span class="n">sqlite3</span><span class="p">.</span><span class="n">connect</span><span class="p">(</span><span class="n">db_file</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Connection Created"</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">sqlite3</span><span class="p">.</span><span class="n">Error</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">e</span>
    <span class="k">return</span> <span class="n">conn</span>


<span class="k">def</span> <span class="nf">close_db</span><span class="p">(</span><span class="n">conn</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">conn</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Connection Closed"</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">sqlite3</span><span class="p">.</span><span class="n">Error</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">e</span>


<span class="k">def</span> <span class="nf">create_table</span><span class="p">(</span><span class="n">conn</span><span class="p">,</span> <span class="n">table_sql</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">conn</span><span class="p">.</span><span class="n">cursor</span><span class="p">()</span>
        <span class="n">c</span><span class="p">.</span><span class="n">execute</span><span class="p">(</span><span class="n">table_sql</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Table Created"</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">sqlite3</span><span class="p">.</span><span class="n">Error</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">e</span>


<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">db_file</span> <span class="o">=</span> <span class="s">"lego.db"</span>

    <span class="n">create_themes_sql</span> <span class="o">=</span> <span class="s">"""
        CREATE TABLE IF NOT EXISTS themes (
            theme_id INT PRIMARY KEY,
            theme_name TEXT NOT NULL
        );
        """</span>
    <span class="n">create_sets_sql</span> <span class="o">=</span> <span class="s">"""
        CREATE TABLE IF NOT EXISTS sets (
            set_num TEXT PRIMARY KEY,
            set_name TEXT NOT NULL,
            set_year INT NOT NULL,
            theme_id INT NOT NULL,
            num_parts INT NOT NULL,
            FOREIGN KEY (theme_id) REFERENCES themes (theme_id)
        );
        """</span>

    <span class="n">conn</span> <span class="o">=</span> <span class="n">connect_db</span><span class="p">(</span><span class="n">db_file</span><span class="p">)</span>
    <span class="n">create_table</span><span class="p">(</span><span class="n">conn</span><span class="p">,</span> <span class="n">create_themes_sql</span><span class="p">)</span>
    <span class="n">create_table</span><span class="p">(</span><span class="n">conn</span><span class="p">,</span> <span class="n">create_sets_sql</span><span class="p">)</span>
    <span class="n">close_db</span><span class="p">(</span><span class="n">conn</span><span class="p">)</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</code></pre></div></div>]]></content><author><name></name></author><summary type="html"><![CDATA[If you spend time around lego sets you will notice that there is a structure between sets, bricks, and themes that is an obvious fit for a relational database system. In this post we will provision a SQLite3 database with Python to hold set and theme information. This will expand on the Counting Lego Bricks post with the end goal of pumping lego data from the Rebrickable API into our local database.]]></summary></entry><entry><title type="html">Counting Lego Bricks</title><link href="http://localhost:4000/2022/09/26/counting-lego-bricks.html" rel="alternate" type="text/html" title="Counting Lego Bricks" /><published>2022-09-26T00:00:00-05:00</published><updated>2022-09-26T00:00:00-05:00</updated><id>http://localhost:4000/2022/09/26/counting-lego-bricks</id><content type="html" xml:base="http://localhost:4000/2022/09/26/counting-lego-bricks.html"><![CDATA[<p>Lego is a big deal around the house and we maintain a running list of all sets acquired over the years. It is pretty easy to track the total number of sets in the collection (currently 62) by just counting up set numbers. From this knowledge a deeper a question was asked:</p>

<blockquote>
  <p>We know how many Lego sets we have, but how many bricks are in the collection?</p>
</blockquote>

<p>With sets on display and large boxes of bricks counting by hand was not an option. Enter the <a href="https://rebrickable.com/downloads/">Rebrickable Lego Database</a>. This database contains data on every set, brick, and minifig released by Lego ever. The best part is that the database is accessible via an <a href="https://rebrickable.com/api/v3/docs/?key=">API</a>. So with a bit of Python we can responsibly interact with the API and count the number of bricks in the collection.</p>

<p>Below is a simple workflow for requesting set data and counting bricks:</p>

<ol>
  <li>Acquire a Rebrickable API token</li>
  <li>Set up a Rebrickable <code class="language-plaintext highlighter-rouge">GET</code> request</li>
  <li>Request data for a list of sets</li>
  <li>Convert response into a <code class="language-plaintext highlighter-rouge">dataframe</code></li>
  <li>Count bricks and report results</li>
</ol>

<h2 id="acquire-api-token">Acquire API token</h2>

<p>Rebrickable requires a unique token to access the Lego database API. A token can can be aquired by:</p>

<ol>
  <li>Make a Rebrickable account <a href="https://rebrickable.com/register">here</a> and login</li>
  <li>Navigate to your account settings and select API</li>
  <li>Copy your 32 character key to an <code class="language-plaintext highlighter-rouge">.env</code> file</li>
  <li>Place the <code class="language-plaintext highlighter-rouge">.env</code> file in the same directory as <code class="language-plaintext highlighter-rouge">lego_api.py</code></li>
</ol>

<p>The <code class="language-plaintext highlighter-rouge">.env</code> should have the following format:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>KEY=&lt;copy 32 character key here&gt;
</code></pre></div></div>

<p>API keys are sensitive information and should be obscured. Using an <code class="language-plaintext highlighter-rouge">.env</code> file will keep the key out of source code and secure access to the Rebrickable API.</p>

<p>Now the key can be accessed in a Python script as an environment variable using the <code class="language-plaintext highlighter-rouge">os</code> and <code class="language-plaintext highlighter-rouge">dotenv</code> modules:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># lego_api.py
</span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>

<span class="c1"># load api key
</span><span class="n">load_dotenv</span><span class="p">()</span>
<span class="n">KEY</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">getenv</span><span class="p">(</span><span class="s">"KEY"</span><span class="p">)</span>

<span class="c1"># set headers
</span><span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">"Accept"</span><span class="p">:</span> <span class="s">"application/json"</span><span class="p">,</span>
        <span class="s">"Authorization"</span><span class="p">:</span> <span class="s">"key "</span> <span class="o">+</span> <span class="n">KEY</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Once the key is loaded and assigned to <code class="language-plaintext highlighter-rouge">KEY</code> it can be used to construct a request header required to to authenticate with the API. Documentation on <code class="language-plaintext highlighter-rouge">dotenv</code> can be found at the <a href="https://pypi.org/project/python-dotenv/">package repository</a> and <code class="language-plaintext highlighter-rouge">os</code> can be referenced in the <a href="https://docs.python.org/3/library/os.html">standard library</a>.</p>

<h2 id="set-up-get-request">Set up GET request</h2>

<p>Now that the API key is set we can construct a <code class="language-plaintext highlighter-rouge">GET</code> request with the <code class="language-plaintext highlighter-rouge">requests </code> package to pull set data from Rebrickable. One of the quirks of the interface is that data can only be returned for one set at a time. So a unique <code class="language-plaintext highlighter-rouge">GET</code> request needs to be made for each set in the collection.</p>

<p>A helper function is used to build the unique  request for a given set and return the data:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># lego-api.py
</span><span class="kn">import</span> <span class="nn">requests</span>

<span class="c1"># helper to run request
</span><span class="k">def</span> <span class="nf">get_sets</span><span class="p">(</span><span class="n">set_id</span><span class="p">):</span>
    <span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"https://rebrickable.com/api/v3/lego/sets/</span><span class="si">{</span><span class="n">set_id</span><span class="si">}</span><span class="s">"</span>
    <span class="n">req</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
    <span class="n">time</span><span class="p">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">1.1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">req</span><span class="p">.</span><span class="n">json</span><span class="p">()</span>
</code></pre></div></div>

<p>The set id is passed as an arguement and then formatted into url string representing the body of the request. Next the request is executed with the url string and authorization header. The response is saved to a variable. Now the function sleeps for 1.1 seconds to avoid abusing the API. The data is extracted from the response as json and returned.</p>

<p>In Python json is effectively treated as a dictionary. The returned set data has the following form:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span>
  <span class="s">"set_num"</span><span class="p">:</span> <span class="s">"31062-1"</span><span class="p">,</span>
  <span class="s">"name"</span><span class="p">:</span> <span class="s">"Robo Explorer"</span><span class="p">,</span>
  <span class="s">"year"</span><span class="p">:</span> <span class="mi">2017</span><span class="p">,</span>
  <span class="s">"theme_id"</span><span class="p">:</span> <span class="mi">672</span><span class="p">,</span>
  <span class="s">"num_parts"</span><span class="p">:</span> <span class="mi">205</span><span class="p">,</span>
  <span class="s">"set_img_url"</span><span class="p">:</span> <span class="s">"https://cdn.rebrickable.com/media/sets/31062-1/9935.jpg"</span><span class="p">,</span>
  <span class="s">"set_url"</span><span class="p">:</span> <span class="s">"https://rebrickable.com/sets/31062-1/robo-explorer/"</span><span class="p">,</span>
  <span class="s">"last_modified_dt"</span><span class="p">:</span> <span class="s">"2018-11-29T23:47:51.919445Z"</span>
<span class="p">}</span>
</code></pre></div></div>

<p>There are several bits of interesting information returned in the set data blob. The <code class="language-plaintext highlighter-rouge">num_parts</code> key wil be directly used to answer our question.</p>

<h2 id="request-set-data">Request set data</h2>

<p>Now that the <code class="language-plaintext highlighter-rouge">get_sets()</code> helper function is in place requests can be efficiently executed for every set number in the collection.</p>

<p>With the help of <code class="language-plaintext highlighter-rouge">pandas</code> and a list comprehension set ids are loaded into a list and <code class="language-plaintext highlighter-rouge">get_sets()</code> is executed for every set in the collection:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># lego-api.py
</span><span class="kn">import</span> <span class="nn">pandas</span>

<span class="c1"># load set ids
</span><span class="n">set_ids</span> <span class="o">=</span> <span class="n">pandas</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"./input_data/sets.csv"</span><span class="p">)[</span><span class="s">"set_num"</span><span class="p">].</span><span class="n">tolist</span><span class="p">()</span>

<span class="c1"># request data for each set
</span><span class="n">set_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">get_sets</span><span class="p">(</span><span class="n">set_id</span><span class="p">)</span> <span class="k">for</span> <span class="n">set_id</span> <span class="ow">in</span> <span class="n">set_ids</span><span class="p">]</span>
</code></pre></div></div>

<p>The output assigned to <code class="language-plaintext highlighter-rouge">set_data</code> is a list of dictionaries. Every dictionary has the same keys and values unique to the set.</p>

<h2 id="convert-to-dataframe-and-count-bricks">Convert to dataframe and count bricks</h2>

<p>Now the accumulated <code class="language-plaintext highlighter-rouge">set_data</code> can be converted to a dataframe and the <code class="language-plaintext highlighter-rouge">num_parts</code> column can be summed to obtain a total brick count:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># lego-api.py
# convert request data to df
</span><span class="n">set_df</span> <span class="o">=</span> <span class="n">pandas</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">set_data</span><span class="p">)</span>

<span class="c1"># count sets
</span><span class="n">sets</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">set_ids</span><span class="p">)</span>

<span class="c1"># count bricks
</span><span class="n">bricks</span> <span class="o">=</span> <span class="n">set_df</span><span class="p">[</span><span class="s">"num_parts"</span><span class="p">].</span><span class="nb">sum</span><span class="p">()</span>

<span class="c1"># report
</span><span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Total bricks in </span><span class="si">{</span><span class="n">sets</span><span class="si">}</span><span class="s"> set collection: </span><span class="si">{</span><span class="n">bricks</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<p>The result is:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; Total bricks in 62 set collection: 23653 
</code></pre></div></div>
<p>That is a lot of bricks.</p>

<p>The full script is given below. This is not the most rigourous approach, but it gets the job done. If this was production grade code the request response codes would be checked, errors would be handled, and there would be unit tests.</p>

<p>The next question is what to do with the blob of data acquired from the Rebrickbable API. One option is dropping set data for the collection into a <code class="language-plaintext highlighter-rouge">SQLite</code> database. From that point it is possible to set up a pipeline to request set data and insert into the database for each new set added to the collection.</p>

<p>That may be a post for another time.</p>

<h2 id="full-script">Full script</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># lego-api.py
</span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">pandas</span>

<span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>

<span class="c1"># load api key
</span><span class="n">load_dotenv</span><span class="p">()</span>
<span class="n">KEY</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">getenv</span><span class="p">(</span><span class="s">"KEY"</span><span class="p">)</span>

<span class="c1"># set headers
</span><span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">"Accept"</span><span class="p">:</span> <span class="s">"application/json"</span><span class="p">,</span>
        <span class="s">"Authorization"</span><span class="p">:</span> <span class="s">"key "</span> <span class="o">+</span> <span class="n">KEY</span>
<span class="p">}</span>

<span class="c1"># helper to run request
</span><span class="k">def</span> <span class="nf">get_sets</span><span class="p">(</span><span class="n">set_id</span><span class="p">):</span>
    <span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"https://rebrickable.com/api/v3/lego/sets/</span><span class="si">{</span><span class="n">set_id</span><span class="si">}</span><span class="s">"</span>
    <span class="n">req</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
    <span class="n">time</span><span class="p">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">1.1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">req</span><span class="p">.</span><span class="n">json</span><span class="p">()</span>

<span class="c1"># load set ids
</span><span class="n">set_ids</span> <span class="o">=</span> <span class="n">pandas</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"./input_data/sets.csv"</span><span class="p">)[</span><span class="s">"set_num"</span><span class="p">].</span><span class="n">tolist</span><span class="p">()</span>

<span class="c1"># request data for each set
</span><span class="n">set_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">get_sets</span><span class="p">(</span><span class="n">set_id</span><span class="p">)</span> <span class="k">for</span> <span class="n">set_id</span> <span class="ow">in</span> <span class="n">set_ids</span><span class="p">]</span>

<span class="c1"># convert request data to df
</span><span class="n">set_df</span> <span class="o">=</span> <span class="n">pandas</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">set_data</span><span class="p">)</span>

<span class="c1"># count sets
</span><span class="n">sets</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">set_ids</span><span class="p">)</span>

<span class="c1"># count bricks
</span><span class="n">bricks</span> <span class="o">=</span> <span class="n">set_df</span><span class="p">[</span><span class="s">"num_parts"</span><span class="p">].</span><span class="nb">sum</span><span class="p">()</span>

<span class="c1"># report
</span><span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Total bricks in </span><span class="si">{</span><span class="n">sets</span><span class="si">}</span><span class="s"> set collection: </span><span class="si">{</span><span class="n">bricks</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

</code></pre></div></div>]]></content><author><name></name></author><summary type="html"><![CDATA[Lego is a big deal around the house and we maintain a running list of all sets acquired over the years. It is pretty easy to track the total number of sets in the collection (currently 62) by just counting up set numbers. From this knowledge a deeper a question was asked:]]></summary></entry><entry><title type="html">Going Pro With Git</title><link href="http://localhost:4000/2022/08/29/going-pro-with-git.html" rel="alternate" type="text/html" title="Going Pro With Git" /><published>2022-08-29T00:00:00-05:00</published><updated>2022-08-29T00:00:00-05:00</updated><id>http://localhost:4000/2022/08/29/going-pro-with-git</id><content type="html" xml:base="http://localhost:4000/2022/08/29/going-pro-with-git.html"><![CDATA[<p>When I first installed Git I did not really know what it was for besides interacting with Github. I learned the basics and got back to whatever project I was working on. Beyond cloning, committing, and pushing my Git skillset did not advance much over time.</p>

<p>Recenty I fell into a challening development situation that prompted me to learn more about Git and version control workflows. I read through the excellent and free <a href="https://git-scm.com/book/en/v2">Pro Git</a> book. This text covers the full spectrum of Git, from the basics of branching through Git’s internal state.</p>

<p>One of the actionable learnings is how to integrate Git with Bash to smooth out workflows and increase project awareness. Below are some notes on how to:</p>

<ol>
  <li>Enable Git command tab completion</li>
  <li>Add Git status info the the prompt</li>
  <li>Set aliases to streamline commands</li>
</ol>

<h2 id="get-source-code">Get source code</h2>

<p>In order to set up tab completion and decorate the prompt we need two scripts packaged with the Git source code:</p>

<ol>
  <li>Clone a copy of Git source from <a href="https://github.com/git/git">Github</a></li>
  <li>Change into the cloned Git directory</li>
  <li>Checkout the tag corresponding to the installed Git version</li>
  <li>Copy <code class="language-plaintext highlighter-rouge">git-completion.bash</code> to home</li>
  <li>Copy <code class="language-plaintext highlighter-rouge">git-prompt.sh</code> to home</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlr@pop-os:~/Desktop<span class="nv">$ </span><span class="nb">cd </span>git
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlr@pop-os:~/Desktop/git <span class="nv">$ </span>git version
git version 2.34.1
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlr@pop-os:~/Desktop/git <span class="nv">$ </span>git checkout tags/v2.34.1
HEAD is now at e9d7761bb9 Git 2.34.1
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlr@pop-os:~/Desktop/git <span class="nv">$ </span><span class="nb">cp </span>contrib/completion/git-completion.bash ~/
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlr@pop-os:~/Desktop/git <span class="nv">$ </span><span class="nb">cp </span>contrib/completion/git-prompt.sh ~/
</code></pre></div></div>

<h2 id="add-tab-completion">Add tab completion</h2>

<p>To set up tab completion the <code class="language-plaintext highlighter-rouge">git-completion.bash</code> script needs to be referenced in the <code class="language-plaintext highlighter-rouge">.bashrc</code>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># git completion</span>
<span class="nb">.</span> ~/git-completion.bash
</code></pre></div></div>

<p>This line can be added where ever it makes sense. I added the reference to the bottom of the configuration file.</p>

<p>Now source the <code class="language-plaintext highlighter-rouge">.bashrc</code> and confirm tab completion:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlr@pop-os:~<span class="nv">$ </span><span class="nb">source</span> .bashrc
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlr@pop-os:~<span class="nv">$ </span>git cl&lt;tab&gt;
clean   clone
</code></pre></div></div>

<h2 id="decorate-prompt">Decorate prompt</h2>

<p>To decorate the shell prompt the <code class="language-plaintext highlighter-rouge">git-prompt.sh</code> script also needs to be referenced in the <code class="language-plaintext highlighter-rouge">.bashrc</code>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># git prompt</span>
<span class="nb">.</span> ~/git-prompt.sh
</code></pre></div></div>

<p>After the script reference set an environment variable to add status markers to the prompt:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># set status marker</span>
<span class="nb">export </span><span class="nv">GIT_PS1_SHOWDIRTYSTATE</span><span class="o">=</span>1
</code></pre></div></div>

<p>Next locate the <code class="language-plaintext highlighter-rouge">PS1</code> prompt string in the <code class="language-plaintext highlighter-rouge">.bashrc</code>, move it to the end of the file, and append the Git prompt format string to it:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># set PS1 </span>
<span class="nb">export </span><span class="nv">PS1</span><span class="o">=</span><span class="s1">'$&lt;current PS1&gt;$(__git_ps1 " (%s)")\$ '</span>
</code></pre></div></div>

<p>This part may require some trial and error to clearly append Git information to the current prompt.</p>

<p>Checkout the comments in <code class="language-plaintext highlighter-rouge">git-prompt.sh</code> for more environment variables and general notes.</p>

<p>Now <code class="language-plaintext highlighter-rouge">source</code> the <code class="language-plaintext highlighter-rouge">.bashrc</code> and change into a directory with a repository. Confirm that a current branch shown with some sort of marker:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlr@pop-os:~/Desktop/rckwzrd.github.io <span class="o">(</span>gh-pages <span class="k">*</span><span class="o">)</span><span class="nv">$ </span>
</code></pre></div></div>

<h2 id="set-aliases">Set Aliases</h2>

<p>Finally, aliases can be set with <code class="language-plaintext highlighter-rouge">git config</code> to shorten or combine commands.</p>

<p>The status command can be shorted with:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git config <span class="nt">--global</span> alias.st status
</code></pre></div></div>

<p>A log command that displays the last 10 commit messages can be created with:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git config <span class="nt">--global</span> alias.ol log <span class="s1">'--pretty=oneline -10'</span>
</code></pre></div></div>]]></content><author><name></name></author><summary type="html"><![CDATA[When I first installed Git I did not really know what it was for besides interacting with Github. I learned the basics and got back to whatever project I was working on. Beyond cloning, committing, and pushing my Git skillset did not advance much over time.]]></summary></entry><entry><title type="html">Linux Host Troubleshooting</title><link href="http://localhost:4000/2022/08/03/linux-host-troubleshooting.html" rel="alternate" type="text/html" title="Linux Host Troubleshooting" /><published>2022-08-03T00:00:00-05:00</published><updated>2022-08-03T00:00:00-05:00</updated><id>http://localhost:4000/2022/08/03/linux-host-troubleshooting</id><content type="html" xml:base="http://localhost:4000/2022/08/03/linux-host-troubleshooting.html"><![CDATA[<p>The text <a href="https://www.goodreads.com/book/show/59879642-devops-for-the-desperate">DevOps for the Desperate</a> covers a range of scenarios for troubleshooting issues on a remote linux host.</p>

<p>Below are notes on each scenario and the tools used to investigate. Basic <code class="language-plaintext highlighter-rouge">cli</code> knowledge, <code class="language-plaintext highlighter-rouge">sudo</code> rights, and <code class="language-plaintext highlighter-rouge">ssh</code> access are assumed.</p>

<h2 id="how-to-troubleshoot">How to troubleshoot</h2>

<p>Before troubleshooting can begin it is important to have a framework to guide the investigation.</p>

<p>The following approach can be used for methodical troubleshooting:</p>

<ol>
  <li>Start simple</li>
  <li>Build mental model</li>
  <li>Develop a theory</li>
  <li>Use consistent tools</li>
  <li>Keep notes</li>
  <li>Ask for help</li>
</ol>

<h2 id="high-load-average">High load average</h2>

<p>The linux metric <code class="language-plaintext highlighter-rouge">load average</code> indicates how busy a host is. CPU usage and disk IO is used to compute the metric. If a host is in an impaired state load average may be a factor.</p>

<p>To troubleshoot first examine load average and then identify processes contributing to a high load.
As a general rule if load average is greater than CPU core count there may be stalled processes impacting performance.</p>

<h3 id="uptime">uptime</h3>

<p>The <code class="language-plaintext highlighter-rouge">uptime</code> command displays how long the host has been running, number of users, and 1/5/15 minute load averages. Note the difference in load times to infer if the host is expierncing a high average load over time. If load is greater than CPU core count, continue investigating.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlr@pop-os:~<span class="nv">$ </span><span class="nb">uptime
 </span>19:28:23 up 16 min,  1 user,  load average: 0.25, 0.43, 0.36
</code></pre></div></div>

<h3 id="top">top</h3>

<p>The <code class="language-plaintext highlighter-rouge">top</code> command provides information about processes running on the host. It provides CPU, memory, and process information. This tool refreshes itself every 3.0 seconds, so let it run for several cycles and note the differences between values.</p>

<p>If a process <code class="language-plaintext highlighter-rouge">PID</code> has high <code class="language-plaintext highlighter-rouge">%CPU</code> or <code class="language-plaintext highlighter-rouge">%MEM</code> it may be contributing to high load averages. The <code class="language-plaintext highlighter-rouge">COMMAND</code> field indicates the name of the process and can be used as a starting point to investigate the further.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlr@pop-os:~<span class="nv">$ </span>top
top - 19:33:09 up 21 min,  1 user,  load average: 0.33, 0.34, 0.34
Tasks: 295 total,   1 running, 294 sleeping,   0 stopped,   0 zombie
%Cpu<span class="o">(</span>s<span class="o">)</span>:  0.1 us,  0.4 sy,  0.0 ni, 99.5 <span class="nb">id</span>,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
MiB Mem :   7663.1 total,   3067.7 free,   2129.3 used,   2466.2 buff/cache
MiB Swap:   4095.5 total,   4095.5 free,      0.0 used.   4625.7 avail Mem 

    PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND                                                
    249 root     <span class="nt">-51</span>   0       0      0      0 S   2.3   0.0   0:16.12 irq/156-DLL0945:00                                     
   1413 root      15  <span class="nt">-5</span> 1386604 114068  69684 S   2.0   1.5   0:32.99 Xorg                                                   
   2261 mlr       15  <span class="nt">-5</span>  635864  54248  40084 S   1.3   0.7   0:08.50 gnome-terminal-                                        
   1614 mlr       15  <span class="nt">-5</span> 5357140 265588 118724 S   1.0   3.4   0:32.49 gnome-shell   
</code></pre></div></div>

<h2 id="high-memory-usage">High memory usage</h2>

<p>Spikes in traffic, memory leaks, or failing applications can cause memory to be consumed at high rates. By design, linux allocates all memory to cache and buffers also making free memory appear low.</p>

<p>The first step is to confirm that the host is really running low on memory or if the kernel is simply swapping cached and buffered memory between processes. Then move to identify the memory consuming processes and handle them.</p>

<h3 id="free">free</h3>

<p>The <code class="language-plaintext highlighter-rouge">free -hm</code> command displays free and used system memory at the time it is run. The <code class="language-plaintext highlighter-rouge">-hm</code> flag outputs memory usage in a human readable format. The <code class="language-plaintext highlighter-rouge">mem:</code> row indicates actual RAM usages while the <code class="language-plaintext highlighter-rouge">swap:</code> row is related to memory written to disk.</p>

<p>If the <code class="language-plaintext highlighter-rouge">free</code> column in the <code class="language-plaintext highlighter-rouge">swap</code> row is low the host is writing memory to the disk and running slow. The <code class="language-plaintext highlighter-rouge">used</code> and <code class="language-plaintext highlighter-rouge">free</code> columns can be misleading. Reference the <code class="language-plaintext highlighter-rouge">available</code> column to get a feel for how much memory is actually available for new processes.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>free <span class="nt">-hm</span>
               total        used        free      shared  buff/cache   available
Mem:           7.5Gi       2.1Gi       3.0Gi       643Mi       2.4Gi       4.5Gi
Swap:          4.0Gi          0B       4.0Gi
</code></pre></div></div>

<h3 id="vmstat">vmstat</h3>

<p>The <code class="language-plaintext highlighter-rouge">vmstat 1 5</code> command provides information about processes, memory, IO, disks, and CPU state. The <code class="language-plaintext highlighter-rouge">1 5</code> arguements will set <code class="language-plaintext highlighter-rouge">vmstat</code> to poll the host for information 5 times every minute. This makes memory trends easier to spot.</p>

<p>The first row of data in the report is system average since boot. The <code class="language-plaintext highlighter-rouge">memory</code> sections provides information on memory moving between <code class="language-plaintext highlighter-rouge">free</code>, <code class="language-plaintext highlighter-rouge">buff</code>, and <code class="language-plaintext highlighter-rouge">cache</code>. The <code class="language-plaintext highlighter-rouge">swap</code> section shows memory being paged in and out of the disk. Low relative free memory and lots of swap activity indicate that the host consuming high rates of free memory and relying swapped disk memory.</p>

<p>The <code class="language-plaintext highlighter-rouge">r</code> column indicates the number of processes waiting to run while the <code class="language-plaintext highlighter-rouge">b</code> column indicates the number of processes sleeping. High count in <code class="language-plaintext highlighter-rouge">r</code> indicates a possible CPU bottleneck. High count in <code class="language-plaintext highlighter-rouge">b</code> indicates that the host is waiting on disk or network I/O.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlr@pop-os:~<span class="nv">$ </span>vmstat 1 5
procs <span class="nt">-----------memory----------</span> <span class="nt">---swap--</span> <span class="nt">-----io----</span> <span class="nt">-system--</span> <span class="nt">------cpu-----</span>
 r  b   swpd   free   buff  cache   si   so    bi    bo   <span class="k">in   </span>cs us sy <span class="nb">id </span>wa st
 2  0      0 3092416 107712 2437708    0    0   137    72  342  468  2  1 97  0  0
 0  0      0 3085652 107712 2443952    0    0     0    96 1309 1748  1  0 99  0  0
 0  0      0 3085400 107712 2441900    0    0     0     0 2976 3101  1  1 99  0  0
 0  0      0 3096512 107712 2439596    0    0     0     0 3068 2655  1  1 99  0  0
 0  0      0 3096260 107712 2439660    0    0     0   112  303  540  0  0 100  0  0

</code></pre></div></div>

<h3 id="ps">ps</h3>

<p>The <code class="language-plaintext highlighter-rouge">ps -efly --sort=-rss | head</code> command provides a snapshot of all running processes and memory usage. The <code class="language-plaintext highlighter-rouge">efly --sort=-rss | head</code> flag sorts the processes by highest memory usage and shows the top ten results. The <code class="language-plaintext highlighter-rouge">CMD</code> column in the output shows the name of each process. The <code class="language-plaintext highlighter-rouge">RSS</code> column gives the amount of memory being used by the process in kilobytes.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ps <span class="nt">-efly</span> <span class="nt">--sort</span><span class="o">=</span><span class="nt">-rss</span> | <span class="nb">head
</span>S UID          PID    PPID  C PRI  NI   RSS    SZ WCHAN  STIME TTY          TIME CMD
S mlr         1807    1578  0  85   5 630440 345151 do_pol 19:12 ?      00:00:08 io.elementary.appcenter <span class="nt">-s</span>
S mlr         1614    1316  2  75  <span class="nt">-5</span> 265828 1347579 do_pol 19:12 ?     00:00:41 /usr/bin/gnome-shell
</code></pre></div></div>

<h2 id="high-iowait">High iowait</h2>

<p>A host has high <code class="language-plaintext highlighter-rouge">iowait</code> when it is spending too much time waiting for disk IO. This metric is measured by tracking the percentage of time a CPU is idle while waiting for IO disk request. High <code class="language-plaintext highlighter-rouge">iowait</code> creates higher average load and CPU usage. Intense application read and writing or slow network storage can be the root cause.</p>

<p>A small amount of <code class="language-plaintext highlighter-rouge">iowait</code> is normal on a modern system. The challenge is differentiating normal <code class="language-plaintext highlighter-rouge">iowait</code> with sustained high <code class="language-plaintext highlighter-rouge">iowait</code> over a period. After identifying high <code class="language-plaintext highlighter-rouge">iowait</code> move to finding the process responsible.</p>

<h3 id="iostat">iostat</h3>

<p>The <code class="language-plaintext highlighter-rouge">iostat -xz 1 20</code> command reports IO and CPU stats for storage devices mounted to the host. The flag <code class="language-plaintext highlighter-rouge">-xz 1 20</code> polls the system 20 times every second and returns an extended statistic format. The <code class="language-plaintext highlighter-rouge">%iowait</code> column will show what percent of time the CPU is waiting on disk requests. The <code class="language-plaintext highlighter-rouge">w/s</code> column indicates the number of writes per second hitting a disk and the <code class="language-plaintext highlighter-rouge">util</code> column indicates disk utilization.</p>

<p>Reviewing polling results for a period of time should help identify if sustained high <code class="language-plaintext highlighter-rouge">iowait</code> is affecting the host.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlr@pop-os:~<span class="nv">$ </span>iostat <span class="nt">-xz</span> 1 20
Linux 5.17.5-76051705-generic <span class="o">(</span>pop-os<span class="o">)</span> 	08/07/2022 	_x86_64_	<span class="o">(</span>8 CPU<span class="o">)</span>

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           1.86    0.23    0.85    0.14    0.00   96.93

Device            r/s     rkB/s   rrqm/s  %rrqm r_await rareq-sz     w/s     wkB/s   wrqm/s  %wrqm w_await wareq-sz     d/s     dkB/s   drqm/s  %drqm d_await dareq-sz     f/s f_await  aqu-sz  %util
dm-0             0.10      2.63     0.00   0.00    0.16    25.65    0.01      0.00     0.00   0.00    0.00     0.44    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
nvme0n1         25.17    938.55    15.53  38.15    0.22    37.28   21.51    520.71    15.15  41.32    1.54    24.20    0.00      0.00     0.00   0.00    0.00     0.00    0.89    0.52    0.04   1.84

</code></pre></div></div>

<h3 id="iotop">iotop</h3>

<p>The <code class="language-plaintext highlighter-rouge">sudo iotop -oPab</code> command displays IO usage relative to processes on the host. It is similiar to <code class="language-plaintext highlighter-rouge">top</code>. The flag <code class="language-plaintext highlighter-rouge">-oPab</code> will constantly poll the host and return cummulative IO stats. Elevated permissions are required to run <code class="language-plaintext highlighter-rouge">iotop</code>. The <code class="language-plaintext highlighter-rouge">IO</code> column will show IO usage and the <code class="language-plaintext highlighter-rouge">PID</code> and <code class="language-plaintext highlighter-rouge">COMMAND</code> columns can be used to identify process.</p>

<p>Reviewing the polling results will help identify what process or proccesses are creating high <code class="language-plaintext highlighter-rouge">iowait</code>.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlr@pop-os:~<span class="nv">$ </span><span class="nb">sudo </span>iotop <span class="nt">-oPab</span>
Total DISK READ:         0.00 B/s | Total DISK WRITE:       443.33 K/s
Current DISK READ:       0.00 B/s | Current DISK WRITE:     391.87 K/s
    PID  PRIO  USER     DISK READ  DISK WRITE  SWAPIN      IO    COMMAND
    352 be/3 root          0.00 B    364.00 K  ?unavailable?  <span class="o">[</span>jbd2/nvme0n1p3-8]
    405 be/4 root          0.00 B     64.00 K  ?unavailable?  systemd-journald
   1077 be/4 root          0.00 B     20.00 K  ?unavailable?  packagekitd
</code></pre></div></div>

<h2 id="out-of-disk-space">Out of disk space</h2>

<p>At some point a host will run out of disk space. This can be caused by an application, accumulated logs, or build up of files. The drive and file system with low disk space needs to be identified first. Then the isolated drive can be searched to locate the files consuming large amounts of disk space.</p>

<h3 id="df">df</h3>

<p>The <code class="language-plaintext highlighter-rouge">df -h</code> command displays disk usage on all mounted filesystems. The flag <code class="language-plaintext highlighter-rouge">-h</code> returns a human readable output. Review the <code class="language-plaintext highlighter-rouge">size</code>, <code class="language-plaintext highlighter-rouge">used</code>, and <code class="language-plaintext highlighter-rouge">use%</code> columns to evaluate what disks under <code class="language-plaintext highlighter-rouge">filesystem</code> are close to capacity.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlr@pop-os:~<span class="nv">$ </span><span class="nb">df</span> <span class="nt">-h</span>
Filesystem      Size  Used Avail Use% Mounted on
tmpfs           767M  1.9M  765M   1% /run
/dev/nvme0n1p3  226G   33G  182G  16% /
tmpfs           3.8G     0  3.8G   0% /dev/shm
tmpfs           5.0M     0  5.0M   0% /run/lock
/dev/nvme0n1p1  497M  362M  136M  73% /boot/efi
/dev/nvme0n1p2  4.0G  2.6G  1.5G  64% /recovery
tmpfs           767M  180K  767M   1% /run/user/1000
</code></pre></div></div>

<h3 id="find">find</h3>

<p>The <code class="language-plaintext highlighter-rouge">sudo find / -type f -size +100M -exec du -ah {} + | sort -hr | head</code> command searches a specified portion of the filesystem for directories and files that match a criteria. In this case the entire command searches the root filesystem for all files greater than 100mb, sorts by size, and then displays the top ten largest files. Elevated permissions are required. Evaluating the output will provide large files to review and a link to the processes filling the disk.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlr@pop-os:~<span class="nv">$ </span><span class="nb">sudo </span>find / <span class="nt">-type</span> f <span class="nt">-size</span> +100M <span class="nt">-exec</span> <span class="nb">du</span> <span class="nt">-ah</span> <span class="o">{}</span> + | <span class="nb">sort</span> <span class="nt">-hr</span> | <span class="nb">head
</span>2.6G	/var/cache/pop-upgrade/recovery.iso
2.4G	/recovery/casper-1FE5-33A5/filesystem.squashfs
666M	/home/mlr/Desktop/export/apple_health_export/export.xml
</code></pre></div></div>

<h2 id="connection-refused">Connection refused</h2>

<p>When a host is impaired its internal APIs may refuse connections over a network. When inspecting application logs a <code class="language-plaintext highlighter-rouge">connection refused</code> error over a port may be observed. Troubleshooting will involve checking network status to and from the host.</p>

<h3 id="curl">curl</h3>

<p>The <code class="language-plaintext highlighter-rouge">curl</code> command is used to check if another webserver is responding to requests. This will help confirm if the impaired host is completely down for all users. If the internal API is impaired a <code class="language-plaintext highlighter-rouge">connection refused</code> or <code class="language-plaintext highlighter-rouge">connection timeout</code> may be returned. This implies the message packet is getting dropped at the host port or firewall.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlr@pop-os:~<span class="nv">$ </span>curl google.com
&lt;HTML&gt;&lt;HEAD&gt;&lt;meta http-equiv<span class="o">=</span><span class="s2">"content-type"</span> <span class="nv">content</span><span class="o">=</span><span class="s2">"text/html;charset=utf-8"</span><span class="o">&gt;</span>
&lt;TITLE&gt;301 Moved&lt;/TITLE&gt;&lt;/HEAD&gt;&lt;BODY&gt;
&lt;H1&gt;301 Moved&lt;/H1&gt;
The document has moved
&lt;A <span class="nv">HREF</span><span class="o">=</span><span class="s2">"http://www.google.com/"</span><span class="o">&gt;</span>here&lt;/A&gt;.
&lt;/BODY&gt;&lt;/HTML&gt;

</code></pre></div></div>

<h3 id="ss">ss</h3>

<p>The <code class="language-plaintext highlighter-rouge">sudo ss -l -n -p | grep 4000</code> command will dump socket information on a host. It can be used to check if the API is actually listening on a port. The flag <code class="language-plaintext highlighter-rouge">-l -n -p</code> pulls all listening sockets, does not resolve <code class="language-plaintext highlighter-rouge">HTTP</code>/<code class="language-plaintext highlighter-rouge">SSH</code>, and reports the process using the process. The output is piped to <code class="language-plaintext highlighter-rouge">grep</code> to search for the desired port. Elevated permissions are required to see all processes.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlr@pop-os:~<span class="nv">$ </span><span class="nb">sudo </span>ss <span class="nt">-l</span> <span class="nt">-n</span> <span class="nt">-p</span> | <span class="nb">grep </span>4000
tcp   LISTEN 0   4096   127.0.0.1:4000    0.0.0.0:<span class="k">*</span>    <span class="nb">users</span>:<span class="o">((</span><span class="s2">"bundle"</span>,pid<span class="o">=</span>5253,fd<span class="o">=</span>8<span class="o">))</span>                                                            
</code></pre></div></div>

<h3 id="tcpdump">tcpdump</h3>

<p>The <code class="language-plaintext highlighter-rouge">sudo tcpdump -ni any tcp port 4000</code> command can be used capture network traffic on a host. This will verify if traffic is reaching the impaired host. Executing the command will begin capturing and inspecting <code class="language-plaintext highlighter-rouge">tcp</code> packets recieved on all interfaces. The flag <code class="language-plaintext highlighter-rouge">-ni any tcp</code> stops <code class="language-plaintext highlighter-rouge">dns</code> resolution and tells <code class="language-plaintext highlighter-rouge">tcpdump</code> to listen for traffic from <code class="language-plaintext highlighter-rouge">8080</code>. Elevated permissions required. Reviewing the flags in the output will show if connections are being refused. If repeated <code class="language-plaintext highlighter-rouge">[S]</code> and <code class="language-plaintext highlighter-rouge">[R]</code> flags are observed this implies that a remote <code class="language-plaintext highlighter-rouge">IP</code> is attempting to sync with the host but the connection is being reset.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlr@pop-os:~<span class="nv">$ </span><span class="nb">sudo </span>tcpdump <span class="nt">-ni</span> any tcp port 4000
tcpdump: data <span class="nb">link type </span>LINUX_SLL2
tcpdump: verbose output suppressed, use <span class="nt">-v</span><span class="o">[</span>v]... <span class="k">for </span>full protocol decode
listening on any, link-type LINUX_SLL2 <span class="o">(</span>Linux cooked v2<span class="o">)</span>, snapshot length 262144 bytes
19:50:24.454916 lo    In  IP 127.0.0.1.56080 <span class="o">&gt;</span> 127.0.0.1.4000: Flags <span class="o">[</span>S], <span class="nb">seq </span>2500379491, win 65495, options <span class="o">[</span>mss 65495,sackOK,TS val 1673811859 ecr 0,nop,wscale 7], length 0
19:50:24.454927 lo    In  IP 127.0.0.1.4000 <span class="o">&gt;</span> 127.0.0.1.56080: Flags <span class="o">[</span>S.], <span class="nb">seq </span>1261009642, ack 2500379492, win 65483, options <span class="o">[</span>mss 65495,sackOK,TS val 1673811859 ecr 1673811859,nop,wscale 7], length 0
19:50:24.454937 lo    In  IP 127.0.0.1.56080 <span class="o">&gt;</span> 127.0.0.1.4000: Flags <span class="o">[</span>.], ack 1, win 512, options <span class="o">[</span>nop,nop,TS val 1673811859 ecr 1673811859], length 0
</code></pre></div></div>]]></content><author><name></name></author><summary type="html"><![CDATA[The text DevOps for the Desperate covers a range of scenarios for troubleshooting issues on a remote linux host.]]></summary></entry><entry><title type="html">Parsing Apple Health Data</title><link href="http://localhost:4000/2022/07/26/parsing-apple-health-data.html" rel="alternate" type="text/html" title="Parsing Apple Health Data" /><published>2022-07-26T00:00:00-05:00</published><updated>2022-07-26T00:00:00-05:00</updated><id>http://localhost:4000/2022/07/26/parsing-apple-health-data</id><content type="html" xml:base="http://localhost:4000/2022/07/26/parsing-apple-health-data.html"><![CDATA[<p>Apple provides easy access to personal health data. The challenge is parsing the blob of data and extracting useful features.</p>

<p>Below is a protocol for streaming heart rate telemetry from a large <code class="language-plaintext highlighter-rouge">xml</code> document into a simple <code class="language-plaintext highlighter-rouge">csv</code> file on a personal linux laptop.</p>

<p>Tools:</p>

<ul>
  <li><a href="https://gist.github.com/hoffa/936db2bb85e134709cd263dd358ca309">original idea</a></li>
  <li><a href="https://docs.python.org/3/library/json.html?highlight=json#module-json">python json module</a></li>
  <li><a href="https://docs.python.org/3/library/xml.etree.elementtree.html">python xml api</a></li>
  <li><a href="https://stedolan.github.io/jq/">jq json processor</a></li>
</ul>

<h2 id="retrieve-health-data">Retrieve health data</h2>

<ol>
  <li>Go to health app on iphone</li>
  <li>Tap profile icon and scroll to bottom</li>
  <li>Select “export all health data” option</li>
  <li>Push <code class="language-plaintext highlighter-rouge">export.zip</code> to cloud storage</li>
  <li>Retrieve and extract archive on local machine</li>
</ol>

<p>The export process may take several minutes. Archive could be 10s of MB.</p>

<p>The extracted health data has the following structure:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>export
└── apple_health_export
    ├── export_cda.xml
    ├── export.xml
    └── workout-routes
        ├── route_2019-03-11_1.19pm.gpx
        ├── route_2019-03-12_1.29pm.gpx
        ├── route_2019-03-13_6.58pm.gpx
        ├── ......
</code></pre></div></div>

<p>All health telemetry is rolled up in the <code class="language-plaintext highlighter-rouge">export.xml</code> file. This file can be 100s of MB.</p>

<p>Within <code class="language-plaintext highlighter-rouge">export.xml</code> the <code class="language-plaintext highlighter-rouge">HKQuantityTypeIdentifierHeartRate</code> record type holds heart rate data:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;Record type="HKQuantityTypeIdentifierHeartRate" 
    ...
    unit="count/min" 
    creationDate="2019-03-02 20:42:24 -0500" 
    startDate="2019-03-02 19:47:18 -0500" 
    endDate="2019-03-02 19:47:18 -0500" 
    value="79"&gt;
    ...
&lt;/Record&gt;
</code></pre></div></div>

<h2 id="parse-heart-rate-data-with-python">Parse heart rate data with python</h2>

<p>Each record in <code class="language-plaintext highlighter-rouge">export.xml</code> can be parsed with the python xml api <code class="language-plaintext highlighter-rouge">iterparse</code> function and filtered using the <code class="language-plaintext highlighter-rouge">HKQuantityTypeIdentifierHeartRate</code> type.</p>

<p>Filtered heart rate records are then converted from <code class="language-plaintext highlighter-rouge">xml</code> to <code class="language-plaintext highlighter-rouge">json</code> and printed to a terminal for the next processing step.</p>

<p>Depending on the size of the <code class="language-plaintext highlighter-rouge">export.xml</code> the python script may run for several minutes:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># parse.py
</span><span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">xml.etree.ElementTree</span> <span class="kn">import</span> <span class="n">iterparse</span>

<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">iterparse</span><span class="p">(</span><span class="n">sys</span><span class="p">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
    <span class="k">if</span> <span class="n">elem</span><span class="p">.</span><span class="n">tag</span> <span class="o">==</span> <span class="s">"Record"</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">elem</span><span class="p">.</span><span class="n">attrib</span><span class="p">[</span><span class="s">"type"</span><span class="p">]</span> <span class="o">==</span> <span class="s">"HKQuantityTypeIdentifierHeartRate"</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="n">json</span><span class="p">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">elem</span><span class="p">.</span><span class="n">attrib</span><span class="p">))</span>
</code></pre></div></div>

<h2 id="stream-heart-rate-json-into-csv-with-jq">Stream heart rate json into csv with jq</h2>

<p>Now that <code class="language-plaintext highlighter-rouge">json</code> like heart rate records are being printed to the terminal they can be picked up in a unix style pipeline.</p>

<p>The pipeline will stream heart rate data into <code class="language-plaintext highlighter-rouge">jq</code> to extract telemetry and then pump formatted data into a clean <code class="language-plaintext highlighter-rouge">csv</code>.</p>

<p>The entire pipeline can be ran in a bash terminal:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python3 parse.py data/export.xml | <span class="se">\</span>
jq <span class="nt">-r</span> <span class="s1">'[.endDate, .type, .unit, .value] | @csv'</span> <span class="se">\</span>
<span class="o">&gt;</span> data/heart_rate.csv
</code></pre></div></div>

<p>Now the fully parsed and neatly formatted heart rate data can be picked up by <code class="language-plaintext highlighter-rouge">pandas</code> and other tools for deeper analysis.</p>

<p>If other records need to be extracted:</p>

<ol>
  <li>Modify the <code class="language-plaintext highlighter-rouge">parse.py</code> script to filter on a given type</li>
  <li>Adjust the arguments in the <code class="language-plaintext highlighter-rouge">jq</code> command</li>
  <li>Define a different <code class="language-plaintext highlighter-rouge">csv</code> name</li>
</ol>

<p>While not the most performant, this method can reliably parse a large Apple health <code class="language-plaintext highlighter-rouge">export.xml</code> on a personal linux laptop.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Apple provides easy access to personal health data. The challenge is parsing the blob of data and extracting useful features. Below is a protocol for streaming heart rate telemetry from a large xml document into a simple csv file on a personal linux laptop. Tools: original idea python json module python xml api jq json processor Retrieve health data Go to health app on iphone Tap profile icon and scroll to bottom Select “export all health data” option Push export.zip to cloud storage Retrieve and extract archive on local machine The export process may take several minutes. Archive could be 10s of MB. The extracted health data has the following structure: export └── apple_health_export ├── export_cda.xml ├── export.xml └── workout-routes ├── route_2019-03-11_1.19pm.gpx ├── route_2019-03-12_1.29pm.gpx ├── route_2019-03-13_6.58pm.gpx ├── ...... All health telemetry is rolled up in the export.xml file. This file can be 100s of MB. Within export.xml the HKQuantityTypeIdentifierHeartRate record type holds heart rate data: &lt;Record type="HKQuantityTypeIdentifierHeartRate" ... unit="count/min" creationDate="2019-03-02 20:42:24 -0500" startDate="2019-03-02 19:47:18 -0500" endDate="2019-03-02 19:47:18 -0500" value="79"&gt; ... &lt;/Record&gt; Parse heart rate data with python Each record in export.xml can be parsed with the python xml api iterparse function and filtered using the HKQuantityTypeIdentifierHeartRate type. Filtered heart rate records are then converted from xml to json and printed to a terminal for the next processing step. Depending on the size of the export.xml the python script may run for several minutes: # parse.py import json import sys from xml.etree.ElementTree import iterparse for _, elem in iterparse(sys.argv[1]): if elem.tag == "Record": if elem.attrib["type"] == "HKQuantityTypeIdentifierHeartRate": print(json.dumps(elem.attrib)) Stream heart rate json into csv with jq Now that json like heart rate records are being printed to the terminal they can be picked up in a unix style pipeline. The pipeline will stream heart rate data into jq to extract telemetry and then pump formatted data into a clean csv. The entire pipeline can be ran in a bash terminal: python3 parse.py data/export.xml | \ jq -r '[.endDate, .type, .unit, .value] | @csv' \ &gt; data/heart_rate.csv Now the fully parsed and neatly formatted heart rate data can be picked up by pandas and other tools for deeper analysis. If other records need to be extracted: Modify the parse.py script to filter on a given type Adjust the arguments in the jq command Define a different csv name While not the most performant, this method can reliably parse a large Apple health export.xml on a personal linux laptop.]]></summary></entry><entry><title type="html">Vpc Fundamentals</title><link href="http://localhost:4000/2022/07/21/vpc-fundamentals.html" rel="alternate" type="text/html" title="Vpc Fundamentals" /><published>2022-07-21T00:00:00-05:00</published><updated>2022-07-21T00:00:00-05:00</updated><id>http://localhost:4000/2022/07/21/vpc-fundamentals</id><content type="html" xml:base="http://localhost:4000/2022/07/21/vpc-fundamentals.html"><![CDATA[<p>Notes on the AWS Virtual Private Cloud (VPC) service.</p>

<p>Fundamental features and links to related topics.</p>

<p>Links:</p>

<ul>
  <li><a href="https://docs.aws.amazon.com/vpc/?id=docs_gateway">AWS VPC docs</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Internet_protocol_suite">Internet protocol suite</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Cloud_computing">Cloud computing</a></li>
  <li><a href="https://en.wikipedia.org/wiki/IPv4">IPv4</a></li>
  <li><a href="https://en.wikipedia.org/wiki/IPv6">IPv6</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing">CIDR</a></li>
</ul>

<h2 id="vpc-overview">VPC overview</h2>

<p>Networks defined in aws cloud</p>

<ul>
  <li>isolated software defined networking</li>
  <li>custom IPv4/v6 address range</li>
  <li>multiple subnets</li>
  <li>routing table configuration</li>
  <li>network address translation (NAT gateway)</li>
  <li>created with console, CLI, or IaC</li>
  <li>security and firewalls</li>
</ul>

<p>Security groups</p>

<ul>
  <li>associated with EC2, allow rules</li>
  <li>stateful</li>
</ul>

<p>Network ACLs</p>

<ul>
  <li>associated with VPCs/subnets</li>
  <li>allow and deny rules</li>
  <li>stateless</li>
</ul>

<h2 id="vpc-deployment-options">VPC deployment options</h2>

<p>Plan cloud network</p>

<ul>
  <li>number and location of networks/subnets</li>
  <li>traffic control in and out
    <ul>
      <li>remote ssh for admin</li>
      <li>public web app in subnet port 80/443</li>
    </ul>
  </li>
  <li>IPv4 address ranges
    <ul>
      <li>CIDR notation /16 /24</li>
    </ul>
  </li>
  <li>network isolation/connectivity
    <ul>
      <li>test vpc sandbox</li>
    </ul>
  </li>
  <li>resources in network
    <ul>
      <li>subnet for public front end</li>
      <li>subnet for private back end database</li>
    </ul>
  </li>
</ul>

<p>VPC Deployment Options</p>

<ul>
  <li>VPC with a single public subnet</li>
  <li>VPC with public and private subnets</li>
  <li>VPC with public and private subnets and hardware VPN</li>
  <li>VPC with private subnet and hardware vpn</li>
</ul>

<p>VPC with a single public subnet</p>

<ul>
  <li>create one subnet and internet gateway</li>
  <li>subnet resources are open to the internet
    <ul>
      <li>elastic and public IPs</li>
    </ul>
  </li>
  <li>control traffic with ACLs and security groups</li>
</ul>

<p>VPC with public and private subnets</p>

<ul>
  <li>one public and one private subnet</li>
  <li>used for multi tier applicatoins
    <ul>
      <li>public subnet for front end</li>
      <li>private subnet for back end</li>
    </ul>
  </li>
  <li>private resources do not have direct outbound internet access
    <ul>
      <li>NAT in public subnet for indirect</li>
    </ul>
  </li>
</ul>

<p>VPC with public and private subnets and hardware VPN</p>

<ul>
  <li>VPN links on premise network to aws
    <ul>
      <li>IPsec VPN tunnel</li>
      <li>aws manages cloud side vpn configuration</li>
      <li>user must configure on premise vpn</li>
    </ul>
  </li>
  <li>on premise traffic to aws elastic Ip
    <ul>
      <li>traverse internet, not VPN</li>
    </ul>
  </li>
  <li>aws private subnet traffic
    <ul>
      <li>routed to on premise network via VPN</li>
    </ul>
  </li>
</ul>

<p>VPC with private subnet and hardware vpn</p>

<ul>
  <li>no internet gateway
    <ul>
      <li>no internet connectivity</li>
    </ul>
  </li>
  <li>extend on premise network into aws</li>
  <li>vpn links on premise network to cloud
    <ul>
      <li>IPsec vpn tunnel</li>
      <li>manage vpn on both ends</li>
    </ul>
  </li>
</ul>

<h2 id="vpc-networking-components">VPC networking components</h2>

<p>VPCs will contain a set of components</p>

<ul>
  <li>subnets</li>
  <li>route tables</li>
  <li>network interfaces</li>
  <li>elastic IP address</li>
  <li>NAT and internet gateways</li>
</ul>

<p>Subnets</p>

<ul>
  <li>contained with vpc</li>
  <li>created within an AZ</li>
  <li>ip address range falls within vpc range
    <ul>
      <li>auto assign ipv4 public ip</li>
    </ul>
  </li>
  <li>ec2 instances deployed into subnets</li>
  <li>associated with network ACLs
    <ul>
      <li>allow/deny inbound/outbound network traffic flow</li>
    </ul>
  </li>
  <li>associated with route tables</li>
</ul>

<p>Route tables</p>

<ul>
  <li>routing control</li>
  <li>internet gateways
    <ul>
      <li>0.0.0.0/0 default route</li>
    </ul>
  </li>
  <li>virtual firewall appliances</li>
  <li>on premise networks through vpn or direct connect</li>
  <li>vpc peering
    <ul>
      <li>private traffic between vpcs</li>
    </ul>
  </li>
</ul>

<p>Network interfaces</p>

<ul>
  <li>elastic network interface
    <ul>
      <li>attached / detached from instances</li>
    </ul>
  </li>
  <li>subnet set at create time</li>
  <li>auto mac address</li>
  <li>ip addressing
    <ul>
      <li>ipv4 or ipv6</li>
      <li>static or dynamic assignment</li>
    </ul>
  </li>
  <li>security groups associated with interface</li>
</ul>

<p>Elastic ip address</p>

<ul>
  <li>static ipv4 address</li>
  <li>linked to aws account</li>
  <li>associated with
    <ul>
      <li>ec2 instance</li>
      <li>network interface</li>
    </ul>
  </li>
  <li>release ip if not needed
    <ul>
      <li>cost $ to use</li>
    </ul>
  </li>
</ul>

<p>Gateways</p>

<ul>
  <li>Network address translation (NAT)
    <ul>
      <li>allow internet connectivity from private subnet</li>
      <li>connections from internet not allowed</li>
      <li>only responses from internet allowed</li>
      <li>modify subnet route tables to use NAT</li>
    </ul>
  </li>
  <li>Internet gateway
    <ul>
      <li>provides subnet access to internet</li>
      <li>connections from internet allowed</li>
      <li>modify subnet route tables to use internet</li>
    </ul>
  </li>
</ul>

<h2 id="ip-addressing-and-subnets">IP addressing and subnets</h2>

<p>Plan out ip addressing prior to vpc and resource deployment.</p>

<ul>
  <li>CIDR notation</li>
  <li>ip address visibility
    <ul>
      <li>public, reachable from internet</li>
      <li>private, used within vpcs</li>
    </ul>
  </li>
  <li>aws supports ipv4 and ipv6</li>
  <li>ip addresses
    <ul>
      <li>associated with network interfaces</li>
      <li>statically or dynamically assigned</li>
    </ul>
  </li>
  <li>ec2 instances recieve an internal dns hostname
    <ul>
      <li>example: ip-10-23-55-1.ec2.internal</li>
      <li>resolvable only within vpc sunet</li>
    </ul>
  </li>
  <li>new ec2 instances
    <ul>
      <li>receive a private ip from subnet is occupies</li>
      <li>address constant between reboots</li>
      <li>address released when instance is terminated</li>
    </ul>
  </li>
  <li>auto assign public ip option</li>
</ul>

<h2 id="create-a-vpc">Create a VPC</h2>

<p>Create vpc through aws console</p>

<ul>
  <li>configuration wizard</li>
  <li>old console style</li>
  <li>ip cidr range and block</li>
  <li>route table and dns</li>
  <li>acl and security group</li>
  <li>subnets</li>
</ul>

<h2 id="automate-deployment-of-infrastructure">Automate deployment of infrastructure</h2>

<p>Deployment tools</p>

<ul>
  <li>powershell (lol)</li>
  <li>aws cli</li>
  <li>api, boto3</li>
  <li>cloud formation IaC</li>
  <li>aws elastic beanstalk and ops works</li>
</ul>

<p>Cloudformation IaC</p>

<ul>
  <li>template file
    <ul>
      <li>json with passed parameters</li>
      <li>custom or preconfigured</li>
    </ul>
  </li>
  <li>related resources deployed quickly</li>
</ul>

<p>Beanstalk</p>

<ul>
  <li>application infrastructure orchestration service</li>
  <li>do not provision individual resources</li>
  <li>upload applications in different languages</li>
</ul>

<p>OpsWorks</p>

<ul>
  <li>centralized application cofiguration managment
    <ul>
      <li>chef and puppet</li>
    </ul>
  </li>
  <li>no manual ec2 configuration</li>
  <li>automate instance
    <ul>
      <li>deployment, configuration, and management</li>
    </ul>
  </li>
  <li>applications consist of
    <ul>
      <li>stacks, resources</li>
      <li>layers, configuration</li>
    </ul>
  </li>
</ul>

<h2 id="security-groups-and-network-acls">Security groups and network ACLs</h2>

<p>Security group</p>

<ul>
  <li>stateful firewall
    <ul>
      <li>supports allow rules</li>
      <li>tracks state of connection</li>
    </ul>
  </li>
  <li>associated with network interfaces
    <ul>
      <li>attached to ec2</li>
    </ul>
  </li>
  <li>consists of acl allow rules
    <ul>
      <li>similiar to a traditional firewall</li>
    </ul>
  </li>
  <li>determine how many security groups
    <ul>
      <li>firewall pools</li>
      <li>one group can be associated withn many interfaces</li>
    </ul>
  </li>
  <li>consistent naming and taging
    <ul>
      <li>track security</li>
    </ul>
  </li>
</ul>

<p>Network ACLs</p>

<ul>
  <li>associated with vpc subnets</li>
  <li>support both allow and deny rules</li>
  <li>stateless firewall
    <ul>
      <li>return traffic is not allowed automatically</li>
    </ul>
  </li>
</ul>

<h2 id="implement-security-groups">Implement security groups</h2>

<ul>
  <li>ec2 console</li>
  <li>network and security</li>
  <li>security groups</li>
  <li>give name, description, vpc, rules, tags</li>
  <li>type, protocol, port, source</li>
  <li>statefull firewall
    <ul>
      <li>do not have to define inbound and outbound rules</li>
    </ul>
  </li>
</ul>

<h2 id="create-internet-gateway">Create internet gateway</h2>

<ul>
  <li>allow access to internet for vpc deployed resources</li>
  <li>vpc dashboard</li>
  <li>subnets</li>
  <li>internet gateway
    <ul>
      <li>state: attached, detached</li>
    </ul>
  </li>
  <li>route table
    <ul>
      <li>connect internet gateway to subnet</li>
    </ul>
  </li>
</ul>

<h2 id="implement-network-acls">Implement network ACLs</h2>

<ul>
  <li>perimeter in and out bound traffic control</li>
  <li>vpc dashboard</li>
  <li>security</li>
  <li>network ACLs</li>
  <li>name and vpc</li>
  <li>default deny all in and out bound</li>
  <li>edit vpc nacl association</li>
</ul>

<h2 id="vpc-connectivity-options">VPC connectivity options</h2>

<p>VPC peering</p>

<ul>
  <li>connectivity between vpc</li>
  <li>different regions and accounts</li>
  <li>no vpn</li>
  <li>ec2 in different vpc communicate</li>
  <li>single vpc peered with multiple vps
    <ul>
      <li>no transitive peering</li>
    </ul>
  </li>
</ul>]]></content><author><name></name></author><summary type="html"><![CDATA[Notes on the AWS Virtual Private Cloud (VPC) service. Fundamental features and links to related topics. Links: AWS VPC docs Internet protocol suite Cloud computing IPv4 IPv6 CIDR VPC overview Networks defined in aws cloud isolated software defined networking custom IPv4/v6 address range multiple subnets routing table configuration network address translation (NAT gateway) created with console, CLI, or IaC security and firewalls Security groups associated with EC2, allow rules stateful Network ACLs associated with VPCs/subnets allow and deny rules stateless VPC deployment options Plan cloud network number and location of networks/subnets traffic control in and out remote ssh for admin public web app in subnet port 80/443 IPv4 address ranges CIDR notation /16 /24 network isolation/connectivity test vpc sandbox resources in network subnet for public front end subnet for private back end database VPC Deployment Options VPC with a single public subnet VPC with public and private subnets VPC with public and private subnets and hardware VPN VPC with private subnet and hardware vpn VPC with a single public subnet create one subnet and internet gateway subnet resources are open to the internet elastic and public IPs control traffic with ACLs and security groups VPC with public and private subnets one public and one private subnet used for multi tier applicatoins public subnet for front end private subnet for back end private resources do not have direct outbound internet access NAT in public subnet for indirect VPC with public and private subnets and hardware VPN VPN links on premise network to aws IPsec VPN tunnel aws manages cloud side vpn configuration user must configure on premise vpn on premise traffic to aws elastic Ip traverse internet, not VPN aws private subnet traffic routed to on premise network via VPN VPC with private subnet and hardware vpn no internet gateway no internet connectivity extend on premise network into aws vpn links on premise network to cloud IPsec vpn tunnel manage vpn on both ends VPC networking components VPCs will contain a set of components subnets route tables network interfaces elastic IP address NAT and internet gateways Subnets contained with vpc created within an AZ ip address range falls within vpc range auto assign ipv4 public ip ec2 instances deployed into subnets associated with network ACLs allow/deny inbound/outbound network traffic flow associated with route tables Route tables routing control internet gateways 0.0.0.0/0 default route virtual firewall appliances on premise networks through vpn or direct connect vpc peering private traffic between vpcs Network interfaces elastic network interface attached / detached from instances subnet set at create time auto mac address ip addressing ipv4 or ipv6 static or dynamic assignment security groups associated with interface Elastic ip address static ipv4 address linked to aws account associated with ec2 instance network interface release ip if not needed cost $ to use Gateways Network address translation (NAT) allow internet connectivity from private subnet connections from internet not allowed only responses from internet allowed modify subnet route tables to use NAT Internet gateway provides subnet access to internet connections from internet allowed modify subnet route tables to use internet IP addressing and subnets Plan out ip addressing prior to vpc and resource deployment. CIDR notation ip address visibility public, reachable from internet private, used within vpcs aws supports ipv4 and ipv6 ip addresses associated with network interfaces statically or dynamically assigned ec2 instances recieve an internal dns hostname example: ip-10-23-55-1.ec2.internal resolvable only within vpc sunet new ec2 instances receive a private ip from subnet is occupies address constant between reboots address released when instance is terminated auto assign public ip option Create a VPC Create vpc through aws console configuration wizard old console style ip cidr range and block route table and dns acl and security group subnets Automate deployment of infrastructure Deployment tools powershell (lol) aws cli api, boto3 cloud formation IaC aws elastic beanstalk and ops works Cloudformation IaC template file json with passed parameters custom or preconfigured related resources deployed quickly Beanstalk application infrastructure orchestration service do not provision individual resources upload applications in different languages OpsWorks centralized application cofiguration managment chef and puppet no manual ec2 configuration automate instance deployment, configuration, and management applications consist of stacks, resources layers, configuration Security groups and network ACLs Security group stateful firewall supports allow rules tracks state of connection associated with network interfaces attached to ec2 consists of acl allow rules similiar to a traditional firewall determine how many security groups firewall pools one group can be associated withn many interfaces consistent naming and taging track security Network ACLs associated with vpc subnets support both allow and deny rules stateless firewall return traffic is not allowed automatically Implement security groups ec2 console network and security security groups give name, description, vpc, rules, tags type, protocol, port, source statefull firewall do not have to define inbound and outbound rules Create internet gateway allow access to internet for vpc deployed resources vpc dashboard subnets internet gateway state: attached, detached route table connect internet gateway to subnet Implement network ACLs perimeter in and out bound traffic control vpc dashboard security network ACLs name and vpc default deny all in and out bound edit vpc nacl association VPC connectivity options VPC peering connectivity between vpc different regions and accounts no vpn ec2 in different vpc communicate single vpc peered with multiple vps no transitive peering]]></summary></entry><entry><title type="html">Five Rules For White Belts</title><link href="http://localhost:4000/2022/07/19/five-rules-for-white-belts.html" rel="alternate" type="text/html" title="Five Rules For White Belts" /><published>2022-07-19T00:00:00-05:00</published><updated>2022-07-19T00:00:00-05:00</updated><id>http://localhost:4000/2022/07/19/five-rules-for-white-belts</id><content type="html" xml:base="http://localhost:4000/2022/07/19/five-rules-for-white-belts.html"><![CDATA[<p>The book <a href="https://www.goodreads.com/en/book/show/38841408-5-rules-for-white-belts">5 Rules for White Belts</a> provides a useful conceptual framework for learning Jiu Jitsu.</p>

<p>Below are notes on the practice and philosophy of the system.</p>

<h2 id="rule-1-you-are-a-work-in-progress">Rule 1: You are a Work In Progress</h2>

<p>Be ok with getting crushed. Failure can be used.</p>

<p>Every session has a choice:</p>

<ol>
  <li>Way of comfort</li>
  <li>Way of growth</li>
</ol>

<p>The choices exist in tension. Comfort provides success and feeds the ego. Growth risks failure but allows for new skills to develop.</p>

<p>Failure must be embraced and risks taken in order to advance. Seek out purposeful failure while training in order to grow.</p>

<h2 id="rule-2-narrow-the-immediate-focus">Rule 2: Narrow the immediate focus</h2>

<p>Focus on the four basic positions of Jiu Jitsu:</p>

<ol>
  <li>guard</li>
  <li>side control</li>
  <li>mount</li>
  <li>back</li>
</ol>

<p>These positions exist in a ladder of dominance:</p>

<ul>
  <li>you have partners back</li>
  <li>you are on top in mount</li>
  <li>you are on top in side control</li>
  <li>you are on top in guard</li>
  <li>you are on bottom in guard</li>
  <li>your partner has side control</li>
  <li>your partner has the mount</li>
  <li>your partner has your back</li>
</ul>

<p>The goal is to ascend and increase control over the other player. The upper half is offensive and the lower half is defensive.</p>

<p>Techniques are the tools used to ascend:</p>

<ul>
  <li>reversals</li>
  <li>guard recoveries</li>
  <li>sweeps</li>
  <li>guard Passes</li>
</ul>

<p>The novice’s goal is to learn how to efficiently use tools to navigate the ladder.</p>

<h2 id="rule-3-learn-how-to-learn">Rule 3: Learn how to learn</h2>

<p>Mat time is finite. Time must be used efficiently to develop skill.</p>

<p>Questions must be asked in order to understand techniques:</p>

<ul>
  <li>what is this?</li>
  <li>how is it done?</li>
  <li>why does it work?</li>
</ul>

<p>If what, how, and why can be articulated for a technique the principle is understood.</p>

<p>Keep a notebook and log training after each session. Review the notes between sessions.</p>

<p>Do not expect the instructor to provide all goals and guidance.</p>

<h2 id="rule-4-be-greatful-for-your-teammates">Rule 4: Be greatful for your teammates</h2>

<p>Jiu Jitsu cannot be practiced alone. The academy is a place for fellowship.</p>

<p>The Jiu Jitsu add:</p>

<blockquote>
  <p>Come work really hard at something incredibly difficult, where grown humans try to choke you. If like being sore, having injuries, and struggling come play Jiu Jitsu.</p>
</blockquote>

<p>Training partners are the obstacles used to develop skill. It is a reciprocral process and growth is not a competition.</p>

<h2 id="rule-5-jiu-jitsu-is-a-vehicle-for-something-more">Rule 5: Jiu Jitsu is a vehicle for something more</h2>

<p>Life is finite and Jiu Jitsu is not a sport to be won. It is a medium for personal development.</p>

<p>Use Jiu Jitsu as a support for the rest of life. Not as a distraction from reality.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[The book 5 Rules for White Belts provides a useful conceptual framework for learning Jiu Jitsu. Below are notes on the practice and philosophy of the system. Rule 1: You are a Work In Progress Be ok with getting crushed. Failure can be used. Every session has a choice: Way of comfort Way of growth The choices exist in tension. Comfort provides success and feeds the ego. Growth risks failure but allows for new skills to develop. Failure must be embraced and risks taken in order to advance. Seek out purposeful failure while training in order to grow. Rule 2: Narrow the immediate focus Focus on the four basic positions of Jiu Jitsu: guard side control mount back These positions exist in a ladder of dominance: you have partners back you are on top in mount you are on top in side control you are on top in guard you are on bottom in guard your partner has side control your partner has the mount your partner has your back The goal is to ascend and increase control over the other player. The upper half is offensive and the lower half is defensive. Techniques are the tools used to ascend: reversals guard recoveries sweeps guard Passes The novice’s goal is to learn how to efficiently use tools to navigate the ladder. Rule 3: Learn how to learn Mat time is finite. Time must be used efficiently to develop skill. Questions must be asked in order to understand techniques: what is this? how is it done? why does it work? If what, how, and why can be articulated for a technique the principle is understood. Keep a notebook and log training after each session. Review the notes between sessions. Do not expect the instructor to provide all goals and guidance. Rule 4: Be greatful for your teammates Jiu Jitsu cannot be practiced alone. The academy is a place for fellowship. The Jiu Jitsu add: Come work really hard at something incredibly difficult, where grown humans try to choke you. If like being sore, having injuries, and struggling come play Jiu Jitsu. Training partners are the obstacles used to develop skill. It is a reciprocral process and growth is not a competition. Rule 5: Jiu Jitsu is a vehicle for something more Life is finite and Jiu Jitsu is not a sport to be won. It is a medium for personal development. Use Jiu Jitsu as a support for the rest of life. Not as a distraction from reality.]]></summary></entry><entry><title type="html">Basic Networking</title><link href="http://localhost:4000/2022/07/14/basic-networking.html" rel="alternate" type="text/html" title="Basic Networking" /><published>2022-07-14T00:00:00-05:00</published><updated>2022-07-14T00:00:00-05:00</updated><id>http://localhost:4000/2022/07/14/basic-networking</id><content type="html" xml:base="http://localhost:4000/2022/07/14/basic-networking.html"><![CDATA[<p>Notes on networking. The absolute basics.</p>

<!--more-->

<p>Based on CompTIA A+ 220-100.</p>

<p><a href="https://en.wikipedia.org/wiki/OSI_model">Wikipedia OSI Model</a></p>

<h2 id="hubs-and-bridges">Hubs and Bridges</h2>

<p>Hubs and bridges are less common these days due to low cost of higher level devices.</p>

<p>Hubs connect computers.</p>

<p>Bridges connect networks segments and nodes.</p>

<p>Hubs</p>

<ul>
  <li>OSI level 1 (physcial level)
    <ul>
      <li>no logic or software</li>
    </ul>
  </li>
  <li>simple device to connect computers</li>
  <li>recieved signals copied to all other ports
    <ul>
      <li>creates noise</li>
    </ul>
  </li>
  <li>active
    <ul>
      <li>signal boosting and repeating</li>
      <li>extend length of network</li>
    </ul>
  </li>
  <li>passive
    <ul>
      <li>no boosting or extension</li>
    </ul>
  </li>
</ul>

<p>Bridges</p>

<ul>
  <li>OSI layer 2 (physcial address aware)
    <ul>
      <li>mac address is the physical hardware address</li>
      <li>logic to bridge traffic between nodes with mac</li>
    </ul>
  </li>
  <li>bridge functions
    <ul>
      <li>join similiar network topologies</li>
      <li>divide network into segments or nodes</li>
      <li>isolate network traffic between nodes</li>
    </ul>
  </li>
  <li>bridges forward broadcast packets
    <ul>
      <li>broadcasts addressed to all computers</li>
    </ul>
  </li>
  <li>cannot perform intelligent network path selection
    <ul>
      <li>route between sender and destination is constant</li>
    </ul>
  </li>
</ul>

<h2 id="switches">Switches</h2>

<p>Switches connect computers. It overtook the hub.</p>

<ul>
  <li>OSI layer 2 (physical address aware)
    <ul>
      <li>use mac to determine where to send data</li>
    </ul>
  </li>
  <li>provides central connectivity between computers</li>
  <li>examine layer 2 header (mac) for info</li>
  <li>uses info to forward packets to correct port
    <ul>
      <li>reduce noise and improves performance</li>
      <li>builds mac address table</li>
      <li>filters traffic</li>
    </ul>
  </li>
  <li>advantage
    <ul>
      <li>increase network bandwidth, security, and performance</li>
      <li>regulates flow of traffic and reduces packet collissions</li>
      <li>mac address are known for all hardware</li>
    </ul>
  </li>
  <li>disadvantage
    <ul>
      <li>difficuly to troubleshoot</li>
      <li>devices can be spoofed</li>
      <li>needs proper design and config</li>
    </ul>
  </li>
  <li>managed (intelligent switch)
    <ul>
      <li>configure over IP with software and dedicated port</li>
    </ul>
  </li>
  <li>unmanaged (plug and play)
    <ul>
      <li>no configuration control</li>
      <li>cost efficient for small deployments</li>
    </ul>
  </li>
</ul>

<h2 id="routers">Routers</h2>

<p>Routers connect networks. It overtook the bridge.</p>

<p>Intelligent devices that find the best path for transmitting data between networks using IP addresses. Routers are required to connect seperate WANs and LANs.</p>

<ul>
  <li>OSI layter 3 (networks)
    <ul>
      <li>IP address</li>
      <li>LAN, WAN, copper, and fiber</li>
      <li>route table programming</li>
    </ul>
  </li>
  <li>routing tables store network addresses
    <ul>
      <li>initial routes</li>
      <li>routing tables can be shared between routers</li>
    </ul>
  </li>
  <li>transmit accross and connect multiple networks
    <ul>
      <li>subnets in a large network</li>
    </ul>
  </li>
  <li>does not forward broadcasts
    <ul>
      <li>isolated broadcast domains</li>
    </ul>
  </li>
  <li>determine best route accross known routes
    <ul>
      <li>consider distance and congestion</li>
    </ul>
  </li>
</ul>

<h2 id="access-points-repeaters-and-extenders">Access Points, Repeaters, and Extenders</h2>

<ul>
  <li>access point
    <ul>
      <li>any point that enables access to network</li>
      <li>“wireless access point”</li>
      <li>“ethernet port in a wall outlet”</li>
    </ul>
  </li>
  <li>repeaters and extender
    <ul>
      <li>operate at layer 1</li>
      <li>improve signal range</li>
      <li>extend wifi network</li>
    </ul>
  </li>
</ul>

<h2 id="network-controllers">Network Controllers</h2>

<p>Network interface cards are used to connect hardware to a switch or network.</p>

<ul>
  <li>network devices require interface
    <ul>
      <li>wireless or wired</li>
    </ul>
  </li>
  <li>can be hardwired or modular</li>
  <li>speed and duplex
    <ul>
      <li>set with auto negotiate</li>
    </ul>
  </li>
  <li>wake on LAN
    <ul>
      <li>turn on hardware with network message</li>
    </ul>
  </li>
</ul>

<h2 id="cable-and-dsl-modems">Cable and DSL Modems</h2>

<p>Hardware devices used to connect to a remote netowrk or internet.</p>

<p>Signal is transmitted in an analog or digital form over long distances. Contraction of modulate and demodulate.</p>

<ul>
  <li>send and recieve data
    <ul>
      <li>telephone and cable lines</li>
    </ul>
  </li>
  <li>dial-up modem
    <ul>
      <li>dial into ISP via telephone</li>
      <li>slow speed 56kbs</li>
    </ul>
  </li>
  <li>digital subscriber line (DSL)
    <ul>
      <li>transfer digital signal over standard telephone</li>
      <li>use DSL modem to connect to ISP</li>
    </ul>
  </li>
  <li>cable modem
    <ul>
      <li>coax tv lines to connect to ISP</li>
      <li>always on and fast data transfer</li>
    </ul>
  </li>
</ul>

<h2 id="patch-panels">Patch Panels</h2>

<p>Structured cabling, patch panels, and network racks.</p>

<ul>
  <li>structured cabling
    <ul>
      <li>bundling and organizing cables</li>
      <li>safety and aesthetics</li>
    </ul>
  </li>
  <li>patch panel
    <ul>
      <li>hardware assembly with many ports</li>
      <li>manages connections to LAN</li>
      <li>types based on ports and cable specs</li>
    </ul>
  </li>
  <li>network racks
    <ul>
      <li>chassis holding patch panels, switches and router</li>
    </ul>
  </li>
</ul>

<h2 id="power-over-ethernet">Power over Ethernet</h2>

<p>Used ethernet cable to carry electrical power. Can place a LAN in area that does not have power.</p>

<ul>
  <li>common for wireless access points</li>
  <li>IEEE 802.3bt next gen POE
    <ul>
      <li>cameras</li>
      <li>LED</li>
      <li>terminals</li>
    </ul>
  </li>
</ul>

<h2 id="ethernet-over-power">Ethernet over Power</h2>

<p>Transmit data using common electrical wiring.</p>

<p>Ideal when it is not possible to run cables or extend WIFI.</p>

<ul>
  <li>requires outlet and adapter</li>
</ul>

<h2 id="firewalls">Firewalls</h2>

<p>Allow or deny conenctions to a network based on a set of rules.</p>

<ul>
  <li>allow or deny connection with rules</li>
  <li>rules are based on IP addresses and ports</li>
  <li>stateful filters maintain session state info</li>
  <li>protect against outside threats</li>
  <li>hardware
    <ul>
      <li>placed between LAN and internet</li>
      <li>port and IP rules</li>
      <li>act as content filter, VPN concentrator, honeypot</li>
    </ul>
  </li>
  <li>software
    <ul>
      <li>runs on host as an app</li>
      <li>control internet access over ports</li>
      <li>is host is compromised so is the firewall</li>
    </ul>
  </li>
  <li>content filters
    <ul>
      <li>component of a firewall</li>
      <li>analyze packets and allow/deny with rules</li>
      <li>common filters include executable, emails, websites</li>
    </ul>
  </li>
</ul>

<h2 id="cloud-network-controllers">Cloud Network Controllers</h2>

<p>Component that controls the flow of traffic from access points through networks. The network controller configures and manages all access points.</p>

<ul>
  <li>on premise or cloud controler backhaul
    <ul>
      <li>communinication is tunneled back to controller</li>
      <li>control plane contains instructions and rules</li>
      <li>data plane is acutal traffic</li>
    </ul>
  </li>
  <li>cloud managed wireless LAN
    <ul>
      <li>virtual controller</li>
      <li>located in public cloud</li>
      <li>connects remote LANS</li>
      <li>controller software and traffic accessed over the web</li>
    </ul>
  </li>
</ul>]]></content><author><name></name></author><summary type="html"><![CDATA[Notes on networking. The absolute basics.]]></summary></entry></feed>